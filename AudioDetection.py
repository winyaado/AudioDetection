# -*- coding: utf-8 -*-
"""balloonpop.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hRI7_2FT_2knHJVVoEEel6yXxocYAd_f

#pip import
"""

!pip install pydub
!pip install moviepy
!pip install ffmpeg-python

import sys
import cv2
import moviepy.editor as mp
from pydub import AudioSegment
import numpy as np
import librosa
import matplotlib.pyplot as plt
import scipy.io.wavfile
import librosa.display
from google.colab import output
import os
import datetime
import glob
from sklearn.svm import SVC
from sklearn.model_selection import cross_val_score, KFold
from scipy.stats import sem
import shutil
import ffmpeg
from google.colab.patches import cv2_imshow
from PIL import Image, ImageDraw, ImageFont

"""#def

def svc
"""

def tsk_svc_1():
  global x_train 
  x_train = list()
  global y_train
  y_train = list()
  files = glob.glob("/content/drive/MyDrive/lab/test1/a/*")
  for file in files:
    data = np.array(AudioSegment.from_mp3(file)[:1000].set_channels(1).get_array_of_samples())
    # 高速フーリエ変換
    F = np.fft.fft(data)
    # 振幅スペクトルを計算
    Amp = np.abs(F)
    x_train.append (Amp)
    y_train.append (1)
    print("\r" + file,end = "")

  files = glob.glob("/content/drive/MyDrive/lab/test1/b/*")
  for file in files:
    data = np.array(AudioSegment.from_mp3(file)[:1000].set_channels(1).get_array_of_samples())
    # 高速フーリエ変換
    F = np.fft.fft(data)
    # 振幅スペクトルを計算
    Amp = np.abs(F)
    x_train.append (Amp)
    y_train.append (2)
    print("\r" + file,end = "")
  print("\r fft end ",end = "")

def evaluate_cross_validation(clf, x, y, K):                        
    cv = KFold(n_splits=K, random_state=0,shuffle=True)
    scores = cross_val_score(clf,x,y,cv=cv)
    print(scores)
    print ("Mean score: {} (+/-{})".format( np.mean (scores), sem(scores)))

def tsk_svc():
  global x_train
  global y_train
  global svc_1

  tsk_svc_1()
  svc_1 = SVC(kernel='rbf')
  evaluate_cross_validation(svc_1,x_train,y_train,5)
  svc_1.fit(x_train,y_train)

"""def 動画処理"""

#config
Durationtime = 1200

def videos_cat(time1,time2,file):
  #mp　遅いからffmpegに変更
  #vram = mp.VideoFileClip(file)
  #vram = vram.subclip(time1,time2)
  #vram.write_videofile("/content/drive/MyDrive/MFC/CAT/" + os.path.basename(file)[:-4] + "." + str(time1) + "-" + str(time2) + ".mp4",threads=4)
  vram = ffmpeg.input(file,ss=time1,t=time2)
  vram = ffmpeg.output(vram,"/content/drive/MyDrive/MFC/CAT/" + os.path.basename(file)[:-4] + "." + str(time1) + "-" + str(time1 + time2) + ".mp4",c="copy")
  ffmpeg.run(vram,overwrite_output=True)

def mfc_raw2cat():
  global Durationtime
  files = glob.glob("/content/drive/MyDrive/MFC/RAW/**/*")
  for file in files:
    duration = float(ffmpeg.probe(file)['streams'][0]['duration'])
    print (str(duration))
    print (file)
    if duration > Durationtime:
      print ("long time videos")
      for x in range(Durationtime,int(duration),Durationtime):
        print ("\r" + str(x),end="")
        videos_cat(x-Durationtime,Durationtime,file)
      videos_cat (x,int(duration),file)
    else:
      print ("short time videos")
      videos_cat (0,int(duration),file)
    print ("--------------------------------------------------")

def mfc_raw2tf():
  global svc_1
  files = glob.glob("/content/drive/MyDrive/MFC/CAT/*")
  for file in files:
    #ファイルサイズが10000000byte 10Mbyte 以下なら削除
    if os.path.getsize(file) < 10000000:
      print ("file size min :" + str(os.path.getsize(file)))
      os.remove(file)
      continue
    outflag = False
    # Extract audio from input video.
    print (file)
    clip_input = mp.VideoFileClip(file).subclip()
    clip_input.audio.write_audiofile('audio.mp3',progress_bar = None)
    sourceAudio = AudioSegment.from_mp3("audio.mp3")
    print ("time:" + str(sourceAudio.duration_seconds) + "/rate:" + str(sourceAudio.frame_rate))
    for x in range (0,int(sourceAudio.duration_seconds),1):
      chapters = list()
      processedAudio = sourceAudio[x*1000:(x*1000)+1000]
      processedAudio = processedAudio.set_channels(1)
      #processedAudio.export("out.mp3", format="mp3")
      data = np.array(processedAudio.get_array_of_samples())
      # 高速フーリエ変換
      F = np.fft.fft(data)
      # 振幅スペクトルを計算
      Amp = np.abs(F)
      if (len(Amp) == 44100):
        if svc_1.predict([Amp]) == [1]:
          outflag = True
          print ("T time:" + str(datetime.timedelta(seconds = x)))
          processedAudio.export("/content/drive/MyDrive/MFC/T/MP3/" + str(datetime.timedelta(seconds = x)) + os.path.basename(file) + ".mp3", format="mp3")
      else:
        print ("オーディオ長さ不正")
    if outflag:
      shutil.move(file, '/content/drive/MyDrive/MFC/T/' + os.path.basename(file))
    else:
      shutil.move(file, '/content/drive/MyDrive/MFC/F/' + os.path.basename(file))
    print ("-----------------------------------------------------------")

def make_mp3zip():
  shutil.make_archive('/content/drive/MyDrive/_ram/ram', 'zip', root_dir='/content/drive/MyDrive/_ram/ram')
  os.rename ("/content/drive/MyDrive/_ram/ram.zip","/content/drive/MyDrive/_ram/" + datetime.datetime.now().strftime('%Y-%m-%d-%H-%M-%S') + ".zip")
  shutil.rmtree("/content/drive/MyDrive/_ram/ram")
  os.mkdir("/content/drive/MyDrive/_ram/ram")
  print (datetime.datetime.now().strftime('%Y-%m-%d-%H-%M-%S') + "ok")

def make_zipsamF():
  shutil.make_archive('/content/drive/MyDrive/MFC/F/sam', 'zip', root_dir='/content/drive/MyDrive/MFC/F/sam')
  os.rename ("/content/drive/MyDrive/MFC/F/ram.zip","/content/drive/MyDrive/MFC/F/" + datetime.datetime.now().strftime('%Y-%m-%d-%H-%M-%S') + ".zip")
  shutil.rmtree("/content/drive/MyDrive/MFC/F/sam")
  os.mkdir("/content/drive/MyDrive/MFC/F/sam")
  print (datetime.datetime.now().strftime('%Y-%m-%d-%H-%M-%S') + "ok")

def sam_picmp4():
  files = glob.glob("/content/drive/MyDrive/MFC/F/sam/*")
  for file in files:
    filesm = glob.glob("/content/drive/MyDrive/MFC/F/*")
    for filem in filesm:
      if os.path.basename(filem) ==  os.path.basename(file[:-4]):
        print("hit:" + os.path.basename(filem) )
        shutil.move(filem , '/content/drive/MyDrive/MFC/F/mov/')

"""def サムネイル"""

def pil2cv(imgPIL):
    imgCV_RGB = np.array(imgPIL, dtype = np.uint8)
    imgCV_BGR = np.array(imgPIL)[:, :, ::-1]
    return imgCV_BGR

def cv2pil(imgCV):
    imgCV_RGB = imgCV[:, :, ::-1]
    imgPIL = Image.fromarray(imgCV_RGB)
    return imgPIL

def cv2_putText(img, text, org, fontFace, fontScale, color):
    x, y = org
    b, g, r = color
    colorRGB = (r, g, b)
    imgPIL = cv2pil(img)
    draw = ImageDraw.Draw(imgPIL)
    fontPIL = ImageFont.truetype(font = fontFace, size = fontScale)
    w, h = draw.textsize(text, font = fontPIL)
    draw.text(xy = (x,y-h), text = text, fill = colorRGB, font = fontPIL)
    imgCV = pil2cv(imgPIL)
    return imgCV

def make_sam_fall():
  files = glob.glob("/content/drive/MyDrive/MFC/F/*")
  for file in files:
    make_sam(file)

def make_sam(file):
  jp_font = "/content/drive/My Drive/lab/fonts/aa.ttf" 
  img_ram = {}
  img_ram1 = {}
  size = 1280,1920, 3
  print(file)
  img_1920 = np.zeros(size, dtype=np.uint8)
  cap_file = cv2.VideoCapture(file)
  print(type(cap_file))
  #正常に読み込めたか？
  if cap_file.isOpened():
    print("動画ファイルオープン")
    #動画詳細情報
    frameMax = cap_file.get(cv2.CAP_PROP_FRAME_COUNT)
    fps = cap_file.get(cv2.CAP_PROP_FPS) 
    cap_file.set(cv2.CAP_PROP_POS_FRAMES, 1)
    ret, frame = cap_file.read()
    if ret:
      height, width, channels = frame.shape[:3]
      resolution = str(width) + "x" + str(height)
      duration = frameMax/fps
      hours = int(duration/60/60)
      minutes = int(duration/60)%60
      seconds = int(duration%60)
      durationout = "{:02}:{:02}:{:02}".format(hours,minutes,seconds)

      for ram1 in range(4):
        for ram2 in range(4):
          f_flag = True
          getframe = (frameMax/17)*((ram1*4)+ram2+1)
          while f_flag:
            cap_file.set(cv2.CAP_PROP_POS_FRAMES, int(getframe))
            ret, frame = cap_file.read()
            if ret:
              frame = cv2.resize(frame,(1920,1080))
              #時間書き出し
              duration = getframe/fps
              hours = int(duration/60/60)
              minutes = int(duration/60)%60
              seconds = int(duration%60)
              cv2.putText(frame,"{:02}:{:02}:{:02}".format(hours,minutes,seconds), (20,120), cv2.FONT_HERSHEY_SIMPLEX, 5, (255,255,255), 8, cv2.LINE_AA)
              img_ram[ram2] = frame
              f_flag = False
            else:
              f_flag = False
              print ("フレームエラー")
              img_ram[ram2] = cv2.resize(np.zeros(size, dtype=np.uint8),(1920,1080))
        img_ram1[ram1] = np.concatenate((img_ram[0],img_ram[1],img_ram[2],img_ram[3]),axis=1)
      img_out = np.concatenate((img_ram1[0],img_ram1[1],img_ram1[2],img_ram1[3]),axis=0)
      img_re = cv2.resize(img_out,(1920,1080))

      x_offset=0
      y_offset=200
      img_1920[y_offset:y_offset+img_re.shape[0], x_offset:x_offset+img_re.shape[1]] = img_re

      img_1920 = cv2_putText(img_1920, 'FileName:'+os.path.basename(file), (int(20),int(50)),jp_font, 35, (255,255,255))
      img_1920 = cv2_putText(img_1920, 'FileSize:'+str(int(os.path.getsize(file)/1000000))+"MB", (int(20),int(90)),jp_font, 35, (255,255,255))
      img_1920 = cv2_putText(img_1920, 'Resolution:'+resolution, (int(20),int(130)),jp_font, 35, (255,255,255))
      img_1920 = cv2_putText(img_1920, 'duration:'+durationout, (int(20),int(170)),jp_font, 35, (255,255,255))

      cv2.imwrite("/content/drive/MyDrive/MFC/F/sam/" + os.path.basename(file) +".jpg" ,img_1920)

      img_1920 = cv2.resize(img_1920,(192,108))
      cv2_imshow(img_1920)

      #読み込みファイルの開放
      cap_file.release()
    else:
      print("初期フレーム読み込みエラー")
  else:
    print("動画ファイルじゃないもの")

"""#main

"""

tsk_svc()

mfc_raw2cat()

mfc_raw2tf()

make_mp3zip()

make_sam_fall()

make_zipsamF()

"""#tool

"""

#@markdown ### videos
videos = "/content/drive/MyDrive/MFC/kitty_devil_MFC_23022021-150740.0-1716.mp4"  #@param {type:"string"}
t_h = 0 #@param {type:"number"} 
t_m =  26#@param {type:"number"}
t_s =  42#@param {type:"number"}

t_a = t_h*60*60 + t_m*60 + t_s

print (str(t_a))
ram = videos
# Extract audio from input video.
clip_input = mp.VideoFileClip(ram).subclip()
clip_input.audio.write_audiofile('audio.mp3',progress_bar = None)
sourceAudio = AudioSegment.from_mp3("audio.mp3")
print ("time:" + str(sourceAudio.duration_seconds) + "/rate:" + str(sourceAudio.frame_rate))
for x in range (t_a-2,t_a+2,1):
  processedAudio = sourceAudio[x*1000:(x*1000)+1000]
  processedAudio = processedAudio.set_channels(1)
  processedAudio.export("/content/drive/MyDrive/_ram/ram/" + os.path.basename(ram) + str(x) + "out.mp3", format="mp3")

"""#testcode

"""

ram = "/content/drive/MyDrive/_どうが/風船/[myfreecams]/kitty_devil - MyFreeCams-1.mp4"
# Extract audio from input video.
clip_input = mp.VideoFileClip(ram).subclip()
clip_input.audio.write_audiofile('audio.mp3')
sourceAudio = AudioSegment.from_mp3("audio.mp3")
print ("time:" + str(sourceAudio.duration_seconds) + "/rate:" + str(sourceAudio.frame_rate))
for x in range (0,int(sourceAudio.duration_seconds),1):
  processedAudio = sourceAudio[x*1000:(x*1000)+1000]
  processedAudio = processedAudio.set_channels(1)
  processedAudio.export("/content/test/" + os.path.basename(ram) + str(x) + "out.mp3", format="mp3")

files = glob.glob("/content/drive/MyDrive/MFC/RAW/36943286_kitty_devil/*")
for file in files:
  print (file)
  set_audio(file)

# coding: utf-8
import sys
import cv2
import moviepy.editor as mp
from pydub import AudioSegment
import numpy as np
import sys
import librosa
import matplotlib.pyplot as plt
import scipy.io.wavfile
import librosa.display
from google.colab import output
import os
import datetime
def set_audio(ram):
  # Extract audio from input video.
  clip_input = mp.VideoFileClip(ram).subclip()
  clip_input.audio.write_audiofile('audio.mp3')
  sourceAudio = AudioSegment.from_mp3("audio.mp3")
  print ("time:" + str(sourceAudio.duration_seconds) + "/rate:" + str(sourceAudio.frame_rate))
  for x in range (0,int(sourceAudio.duration_seconds),1):
    processedAudio = sourceAudio[x*1000:(x*1000)+1000]
    processedAudio = processedAudio.set_channels(1)
    #processedAudio.export("out.mp3", format="mp3")
    data = np.array(processedAudio.get_array_of_samples())
    # 高速フーリエ変換
    F = np.fft.fft(data)
    # 振幅スペクトルを計算
    Amp = np.abs(F)
    if (len(Amp) == 44100):
      outstring = "F"
      if svc_1.predict([Amp]) == [1]:
        outstring = "T"
        print ("T time:" + str(datetime.timedelta(seconds = x)))
        processedAudio.export("/content/drive/MyDrive/_ram/ram/"+ outstring + str(datetime.timedelta(seconds = x)) + os.path.basename(ram) + "out.mp3", format="mp3")
      print ("time:" + str(datetime.timedelta(seconds = x)))
    else:
      print ("オーディオ長さ不正")




set_audio("/content/drive/MyDrive/MFC/RAW/36943286_kitty_devil/kitty_devil_MFC_19022021-120544.mp4")